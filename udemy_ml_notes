***************************
*** Notes Online Course ***
***************************


--- PART 2 - Regression Models ---
SLR:
     y      = b0 + b1 * x1          //astraight best line, trend 
     salary = b0 + b1 * Experience
y dependend var DV
x independent var IV
b0 constant (where line crosses y)
b1 the coefficient, a unit change (slope)

The line is the modelled data
- take + or - distance, square them SUM(y-y^)^2

* So once data is prepared, lets use Python to apply SLR model to it :) 



--- PART 1 - Data preprocessing ---
* In the dataset, find out the independent and dependent cols 
* When running file in python anaconda console: 
  <highlight then control + enter> 
* In R we dont need

* Based on the dataset, lets set to X the MATRIX OF FEATURES, 
* to y the DEPENDEND DATA
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 3].values

* Rows are OBSERVATIONS
* Columns are the FEATURES, and DEPENDEND DATA

* Missing data: use mean

* PenUltimateluy transform relevant cols into Categorical Data
  - So to have only mathematical data in equations, not strings
  - Dummy vars (mask) so to avoid that anything is greater than the other s
  - Now same in R..it's simpler
  
* Eventually, split your data set into the actual training set, and test set
  - This is absolutely required for any ML to see it's working correctly
  - Effectively declare a subset to be the test set, but how to select:
  - Most importantly avoid overfitting (0.2 for Test is usually cool)
  
* Feature Scaling
  - Here: Age and Salary is not on a scale 
  - Euclidian Distance (square of x(age),y(salary)) not at all same scale
  - so standardisation and normalisation necessary > no domination
  - Also, makes ML much faster
  
--- PART 0 - Requirements ---

R Studio
Python 3.5 + Anaconda IDE (numPy, Pandas..)